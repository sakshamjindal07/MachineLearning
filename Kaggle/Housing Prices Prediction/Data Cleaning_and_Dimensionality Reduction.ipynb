{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\") # read train data\n",
    "test = pd.read_csv(\"test.csv\") # read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#log transform the features\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "def logTransform (train,test):\n",
    "    \n",
    "    numerical_features=test.select_dtypes(include=[\"float\",\"int\",\"bool\"]).columns.values\n",
    "    dataframes = [train,test]\n",
    "    \n",
    "    for df in dataframes:\n",
    "        \n",
    "        skewed_feats = df[numerical_features].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "        skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "        skewed_feats = skewed_feats.index\n",
    "        df[skewed_feats] = np.log1p(df[skewed_feats])\n",
    "        \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features(train, test):\n",
    "    trainval = list(train.columns.values) # list train features\n",
    "    testval = list(test.columns.values) # list test features\n",
    "    output = list(set(trainval) & set(testval)) # check wich features are in common (remove the outcome column)\n",
    "    output.remove('Id') # remove non-usefull id column\n",
    "\n",
    "    return output\n",
    "\n",
    "def process_features(train,test):\n",
    "    tables=[test,train]\n",
    "    print (\"Handling missing values...\")\n",
    "    total_missing=train.isnull().sum()\n",
    "    to_delete=total_missing[total_missing>(1460/3.)] # select features with more than 1/3 missing values\n",
    "    for table in tables:\n",
    "        table.drop(to_delete.index.tolist(),axis=1, inplace=True)\n",
    "            \n",
    "    print (\"Filling Nan...\")\n",
    "    numerical_features=test.select_dtypes(include=[\"float\",\"int\",\"bool\"]).columns.values\n",
    "    categorical_features=train.select_dtypes(include=[\"object\"]).columns.values\n",
    "    for table in tables: \n",
    "        for feature in numerical_features: \n",
    "            table[feature].fillna(train[feature].median(), inplace = True) # replace by median value\n",
    "        for feature in categorical_features: \n",
    "            table[feature].fillna(train[feature].value_counts().idxmax(), inplace = True) # replace by most frequent value\n",
    "\n",
    "    #print (\"Handling categorical features...\")\n",
    "    #for feature in categorical_features: # Encode categorical features\n",
    "    #   le = preprocessing.LabelEncoder()\n",
    "    #   le.fit(train[feature])\n",
    "    #   for table in tables: \n",
    "    #       table[feature]=le.transform(table[feature])\n",
    "    \n",
    "    print (\"Getting features...\")\n",
    "    features = get_features(train,test)\n",
    "    \n",
    "    return train,test,features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDummies(df):\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df_str = df.select_dtypes(include=['object']) \n",
    "    df.drop(df_str.columns.values,axis=1,inplace=True)  \n",
    "    df_str_dum = pd.get_dummies(df_str)\n",
    "    \n",
    "    return df_str_dum\n",
    "\n",
    "def labelEncoding(train,test):\n",
    "    \n",
    "    train_str_dum = getDummies(train)\n",
    "    test_str_dum  = getDummies(test)\n",
    "    columns_dum = list(set(train_str_dum) & set(test_str_dum))\n",
    "\n",
    "    train_str_dum = train_str_dum[columns_dum]\n",
    "    test_str_dum = test_str_dum[columns_dum]\n",
    "\n",
    "    #New train and New test\n",
    "    train_flo = train.select_dtypes(exclude=['object'])\n",
    "    test_flo = test.select_dtypes(exclude=['object']) \n",
    "\n",
    "    new_train = pd.merge(train_flo,train_str_dum,left_index=True,right_index=True)\n",
    "    new_test = pd.merge(test_flo,test_str_dum,left_index=True,right_index=True)\n",
    "    \n",
    "    return new_train , new_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DimensionalityReduction(new_train,new_test):\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.decomposition import PCA, KernelPCA, TruncatedSVD, SparsePCA\n",
    "    \n",
    "    train_clf = new_train.copy()\n",
    "    train_clf.drop('Id',axis=1,inplace=True)\n",
    "    index = pd.DataFrame(test.Id,columns = ['Id'])\n",
    "    test_clf = new_test.drop('Id',axis=1)\n",
    "    train_clf1 = train_clf.copy()\n",
    "    train_clf1['tot_sf'] = train_clf1['TotalBsmtSF'] + train_clf1['GrLivArea']\n",
    "    train_clf1['ratio_fl'] = train_clf1['2ndFlrSF'] / train_clf1['1stFlrSF'] \n",
    "    train_clf1['garage_ex'] = (train_clf1['GarageQual_Gd'] + train_clf1['GarageQual_TA'] + train_clf1['GarageQual_Fa'] + train_clf1['GarageQual_Po']) * (train_clf1['GarageCond_Ex'])\n",
    "  \n",
    "    clus = KernelPCA(n_components = 25)\n",
    "    train_clf2_pca = clus.fit_transform(train_clf1)\n",
    "    train_clf2_pca = pd.DataFrame(train_clf2_pca)\n",
    "    print(train_clf2_pca.shape)\n",
    "    print(train_clf2_pca.columns)\n",
    "    print(train_clf1.columns)\n",
    "    train_clf2 = pd.merge(train_clf1,train_clf2_pca,left_index=True,right_index=True)\n",
    "\n",
    "    test_clf2 = test_clf.drop(['LotFrontage','MasVnrArea','GarageYrBlt'],axis=1)\n",
    "    test_clf2 = pd.merge(test_clf2,test[['LotFrontage','MasVnrArea','GarageYrBlt']],left_index=True,right_index=True)\n",
    "    test_clf2['tot_sf'] = test_clf2['TotalBsmtSF'] + test_clf2['GrLivArea']\n",
    "    test_clf2['ratio_fl'] = test_clf2['2ndFlrSF']  / test_clf2['1stFlrSF']\n",
    "    test_clf2['garage_ex'] = (test_clf2['GarageQual_Gd'] + test_clf2['GarageQual_TA'] + test_clf2['GarageQual_Fa'] + test_clf2['GarageQual_Po']) * (test_clf2['GarageCond_Ex'])\n",
    "\n",
    "    test_clf3 = pd.merge(test_clf2,pd.DataFrame(clus.transform(test_clf2)),left_index=True,right_index=True)\n",
    "\n",
    "    index = pd.DataFrame(test.Id,columns = ['Id'])\n",
    "    \n",
    "    return train_clf3,test_clf3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Filling Nan...\n",
      "Getting features...\n",
      "(1460, 76) (1459, 255)\n",
      "(1460, 256) (1459, 255)\n"
     ]
    }
   ],
   "source": [
    "train,test,features = process_features(train,test)\n",
    "new_train,_new_test = logTransform(train,test)\n",
    "print(new_train.shape, new_test.shape)\n",
    "new_train , new_test = labelEncoding(train,test)\n",
    "print(new_train.shape, new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new_train , new_test = DimensionalityReduction(new_train,new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write to new files\n",
    "\n",
    "new_train.to_csv('train_cleaned.csv',index=False)\n",
    "new_test.to_csv('test_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
