{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After exploring the data, we're going to find of much of it can be relevant for our decision tree. This is a critical point for every Data Science project, since too much train data can easily result in bad model generalisation (accuracy on test/real/unseen observations). \n",
    "\n",
    "In this Ipython notebook, I am going to cover Random Forest. Random Forest is a versatile machine learning method capable of performing both regression and classification tasks. It also undertakes dimensional reduction methods, treats missing values, outlier values and other essential steps of data exploration, and does a fairly good job. It is a type of ensemble learning method, where a group of weak models combine to form a powerful model.\n",
    "\n",
    "Advantages of Random Forest:\n",
    "\n",
    "1) This algorithm can solve both type of problems i.e. classification and regression and does a decent estimation at both fronts.\n",
    "      \n",
    "2) One of benefits of Random forest which excites me most is, <B> the power of handle large data set with higher dimensionality. It can handle thousands of input variables and identify most significant variables so it is considered as one of the dimensionality reduction methods. </B>  Further, the model outputs Importance of variable, which can be a very handy feature (on some random data set).\n",
    "\n",
    "3) It has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing.\n",
    "\n",
    "4) It has methods for balancing errors in data sets where classes are imbalanced.\n",
    "\n",
    "5) The capabilities of the above can be extended to unlabeled data, leading to unsupervised clustering, data views and outlier detection.\n",
    "\n",
    "6) Random Forest involves sampling of the input data with replacement called as bootstrap sampling. Here one third of the data is not used for training and can be used to testing. These are called the out of bag samples. Error estimated on these out of bag samples is known as out of bag error. Study of error estimates by Out of bag, gives evidence to show that the out-of-bag estimate is as accurate as using a test set of the same size as the training set. Therefore, using the out-of-bag error estimate removes the need for a set aside test set.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Functional_Min2</th>\n",
       "      <th>BldgType_Twnhs</th>\n",
       "      <th>RoofStyle_Mansard</th>\n",
       "      <th>RoofMatl_CompShg</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "      <th>GarageCond_Ex</th>\n",
       "      <th>Functional_Maj2</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>GarageType_BuiltIn</th>\n",
       "      <th>Exterior2nd_CBlock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>80</td>\n",
       "      <td>9.360741</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.150603</td>\n",
       "      <td>4.976734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.044522</td>\n",
       "      <td>81</td>\n",
       "      <td>9.565775</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>4.691348</td>\n",
       "      <td>6.828712</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>74</td>\n",
       "      <td>9.534668</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.674561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.110874</td>\n",
       "      <td>78</td>\n",
       "      <td>9.208238</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>6.401917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.795791</td>\n",
       "      <td>43</td>\n",
       "      <td>8.518392</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.575949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 254 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0    3.044522           80  9.360741            5            6       1961   \n",
       "1    3.044522           81  9.565775            6            6       1958   \n",
       "2    4.110874           74  9.534668            5            5       1997   \n",
       "3    4.110874           78  9.208238            6            6       1998   \n",
       "4    4.795791           43  8.518392            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2         ...          \\\n",
       "0          1961    0.000000    6.150603    4.976734         ...           \n",
       "1          1958    4.691348    6.828712    0.000000         ...           \n",
       "2          1998    0.000000    6.674561    0.000000         ...           \n",
       "3          1998    3.044522    6.401917    0.000000         ...           \n",
       "4          1992    0.000000    5.575949    0.000000         ...           \n",
       "\n",
       "   Functional_Min2  BldgType_Twnhs  RoofStyle_Mansard  RoofMatl_CompShg  \\\n",
       "0                0               0                  0                 1   \n",
       "1                0               0                  0                 1   \n",
       "2                0               0                  0                 1   \n",
       "3                0               0                  0                 1   \n",
       "4                0               0                  0                 1   \n",
       "\n",
       "   SaleCondition_Partial  GarageCond_Ex  Functional_Maj2  SaleType_New  \\\n",
       "0                      0              0                0             0   \n",
       "1                      0              0                0             0   \n",
       "2                      0              0                0             0   \n",
       "3                      0              0                0             0   \n",
       "4                      0              0                0             0   \n",
       "\n",
       "   GarageType_BuiltIn  Exterior2nd_CBlock  \n",
       "0                   0                   0  \n",
       "1                   0                   0  \n",
       "2                   0                   0  \n",
       "3                   0                   0  \n",
       "4                   0                   0  \n",
       "\n",
       "[5 rows x 254 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_cleaned.csv')\n",
    "test_df  = pd.read_csv('test_cleaned.csv')\n",
    "\n",
    "id = test_df['Id']\n",
    "train_df.drop('Id',axis = 1, inplace = True)\n",
    "test_df.drop('Id',axis = 1 , inplace = True)\n",
    "y_train = train_df['SalePrice']\n",
    "x_train = train_df.drop('SalePrice', axis = 1)\n",
    "\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()\n",
    "feat_labels = train_df.columns.values\n",
    "#feat_labels\n",
    "x_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, Random Forest is good regression method which has an ability to handle a large amount of high-dimensional data ( here we have ~ 280 columns as features), we are going to construct a function which handles the features and list the features which are important in prediction.Also , I am going to construct a function which fits a given model to the train data and cross validates via K-Fold Cross Validation Scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def printFeature(model,x_train, y_train , performCV = True , cvFolds = 10):\n",
    "    \n",
    "    model.fit(x_train,y_train)\n",
    "    feature_importances = model.feature_importances_\n",
    "    feat_labels = [ x for x in x_train.columns.values]\n",
    "    feat_imp = pd.Series(feature_importances,feat_labels).sort_values(ascending=False)\n",
    "    #print(feat_imp.dtypes)\n",
    "    #plt.bar(feat_labels[:],feat_imp[:])\n",
    "    plt.ylabel('Feature Importances')\n",
    "    #plt.show()\n",
    "    \n",
    "def modelFit(model,x_train,y_train,performCV = True , cvFolds = 10):\n",
    "    \n",
    "    model.fit(x_train,y_train)\n",
    "    x_train_predictions = model.predict(x_train)\n",
    "    \n",
    "    if performCV == True :\n",
    "        cv_score_meanSqError = cross_val_score(model,x_train,y_train,cv= cvFolds,scoring = 'mean_squared_error')\n",
    "        cv_score_r2 = cross_val_score(model,x_train,y_train,cv= cvFolds,scoring = 'r2')\n",
    "        \n",
    "    print(\" Model Report\")\n",
    "    print(\" Mean Squared Error = %.4g\" % metrics.mean_squared_error(y_train.values,x_train_predictions))\n",
    "    print(\" R2 score = %.4g\" % metrics.r2_score(y_train.values,x_train_predictions))\n",
    "          \n",
    "    \n",
    "    print(\" CV Score (Mean Square Error) : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score_meanSqError),np.std(cv_score_meanSqError),np.min(cv_score_meanSqError),np.max(cv_score_meanSqError)))\n",
    "    print(\" CV Score ( R square        ) : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score_r2),np.std(cv_score_r2),np.min(cv_score_r2),np.max(cv_score_r2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model Report\n",
      " Mean Squared Error = 0.002689\n",
      " R2 score = 0.9831\n",
      " CV Score (Mean Square Error) : Mean - -0.02019539 | Std - 0.002728923 | Min - -0.02373028 | Max - -0.01596594\n",
      " CV Score ( R square        ) : Mean - 0.8733335 | Std - 0.0115757 | Min - 0.8545422 | Max - 0.8896669\n"
     ]
    }
   ],
   "source": [
    "#defining the model\n",
    "n_estimators = 1000\n",
    "random_state = 0\n",
    "n_jobs = -1\n",
    "rf = RandomForestRegressor(n_estimators = n_estimators,random_state = random_state,n_jobs = n_jobs) \n",
    "#printFeature(rf,x_train,y_train)\n",
    "modelFit(rf,x_train,y_train,performCV = True, cvFolds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<B> Parameter Tunign of the Random Forest Model </B> :\n",
    "\n",
    "We will use grid search to identify the optimal parameters of our random forest model. Because our training dataset is quite small, we can get away with testing a wider range of hyperparameter values.I will discuss the results of this grid search. I will tune :\n",
    "\n",
    "n_estimators = Signifies the number of trees used in random forest\n",
    "\n",
    "and then tune tree specific paramters here :\n",
    "1) min_samples_split\n",
    "2) min_smaples_leaf\n",
    "3) max_depth\n",
    "4) min_leaf_nodes\n",
    "5) max_features\n",
    "6) loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=10,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': array([1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000,\n",
       "       6500, 7000, 7500, 8000, 8500, 9000, 9500])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tuning the no. of trees used in the regresor\n",
    "\n",
    "param_test1 =  {'n_estimators':np.arange(1000,10000,500)}\n",
    "rfr = RandomForestRegressor(min_samples_split=2,min_samples_leaf=1,max_depth=8,max_features='sqrt',random_state=10)\n",
    "gridSearch1 =  GridSearchCV(estimator = rfr, \n",
    "                       param_grid = param_test1, scoring='r2',n_jobs=4,iid=False, cv=5)\n",
    "gridSearch1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.48082, std: 0.01574, params: {'n_estimators': 1000},\n",
       "  mean: 0.48570, std: 0.01560, params: {'n_estimators': 1500},\n",
       "  mean: 0.48465, std: 0.01530, params: {'n_estimators': 2000},\n",
       "  mean: 0.48475, std: 0.01519, params: {'n_estimators': 2500},\n",
       "  mean: 0.48500, std: 0.01495, params: {'n_estimators': 3000},\n",
       "  mean: 0.48415, std: 0.01530, params: {'n_estimators': 3500},\n",
       "  mean: 0.48442, std: 0.01527, params: {'n_estimators': 4000},\n",
       "  mean: 0.48381, std: 0.01536, params: {'n_estimators': 4500},\n",
       "  mean: 0.48366, std: 0.01545, params: {'n_estimators': 5000},\n",
       "  mean: 0.48314, std: 0.01547, params: {'n_estimators': 5500},\n",
       "  mean: 0.48250, std: 0.01538, params: {'n_estimators': 6000},\n",
       "  mean: 0.48232, std: 0.01545, params: {'n_estimators': 6500},\n",
       "  mean: 0.48238, std: 0.01544, params: {'n_estimators': 7000},\n",
       "  mean: 0.48216, std: 0.01550, params: {'n_estimators': 7500},\n",
       "  mean: 0.48204, std: 0.01549, params: {'n_estimators': 8000},\n",
       "  mean: 0.48163, std: 0.01548, params: {'n_estimators': 8500},\n",
       "  mean: 0.48179, std: 0.01534, params: {'n_estimators': 9000},\n",
       "  mean: 0.48152, std: 0.01549, params: {'n_estimators': 9500}],\n",
       " {'n_estimators': 1500},\n",
       " 0.4857005784495668)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch1.grid_scores_, gridSearch1.best_params_ , gridSearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f9255bca5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f9255bca5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'CE7ADA908716473F9D6167D438276510']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'CE7ADA908716473F9D6167D438276510'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-ca3d5ac98d81>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'import warnings\\nwarnings.filterwarnings(\"ignore\"...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...in_df.drop('SalePrice', axis = 1)\\n\\ntest_df.head()\", 'y_train.head()\\nfeat_labels = train_df.columns.values\\n#feat_labels\\nx_train.isnull().values.any()', 'from sklearn.ensemble import RandomForestRegress...ore_r2),np.min(cv_score_r2),np.max(cv_score_r2)))', 'from sklearn.grid_search import GridSearchCV', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'], 'Out': {3:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], 4: False}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': False, '_3':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '_4': False, '__':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '___': '', '__builtin__': <module 'builtins' (built-in)>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'import warnings\\nwarnings.filterwarnings(\"ignore\"...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...in_df.drop('SalePrice', axis = 1)\\n\\ntest_df.head()\", 'y_train.head()\\nfeat_labels = train_df.columns.values\\n#feat_labels\\nx_train.isnull().values.any()', 'from sklearn.ensemble import RandomForestRegress...ore_r2),np.min(cv_score_r2),np.max(cv_score_r2)))', 'from sklearn.grid_search import GridSearchCV', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'], 'Out': {3:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], 4: False}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': False, '_3':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '_4': False, '__':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '___': '', '__builtin__': <module 'builtins' (built-in)>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/saksham/Machine Learning/Kaggle/Housing Prices Prediction/<ipython-input-8-ca3d5ac98d81> in <module>()\n      1 # Tuning max_depth and min_samples_split\n      2 \n      3 param_test2 =  {'max_depth':np.arange(7,9,1), 'min_samples_split':np.arange(1,11,2)}\n      4 rfr = RandomForestRegressor(n_estimators=1500,max_features='sqrt', random_state=0)\n      5 gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test2 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n----> 6 gridSearch2.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='r2', verbose=0)>\n        X =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns]\n        y = 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64\n        self.param_grid = {'max_depth': array([7, 8]), 'min_samples_split': array([1, 3, 5, 7, 9])}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Mar  9 20:06:51 2017\nPID: 3372                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'max_depth': 7, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...state=0,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 1499\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=1500, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...        random_state=209652396, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  1.,  1., ...,  0.,  2.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1665, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\", line 326, in fit\n    for i, t in enumerate(trees))\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 758, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 608, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 571, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 109, in apply_async\n    result = ImmediateResult(func)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 326, in __init__\n    self.results = batch()\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\", line 120, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py\", line 1029, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py\", line 199, in fit\n    % self.min_samples_split)\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Mar  9 20:06:51 2017\nPID: 3372                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'max_depth': 7, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...state=0,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 1499\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=1500, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...        random_state=209652396, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  1.,  1., ...,  0.,  2.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Mar  9 20:06:51 2017\nPID: 3372                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'max_depth': 7, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...state=0,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 1499\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=1500, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...        random_state=209652396, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  1.,  1., ...,  0.,  2.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ca3d5ac98d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgridSearch2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_test2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgridSearch2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m                 for train, test in cv)\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7f9255bca5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f9255bca5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'CE7ADA908716473F9D6167D438276510']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'CE7ADA908716473F9D6167D438276510'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T20:06:48.087588', 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'session': 'CE7ADA908716473F9D6167D438276510', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '9634A8315E1449F288A2EE8E8B8AE923', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-8-ca3d5ac98d81>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f92176896f0, file \"<ipython-input-8-ca3d5ac98d81>\", line 6>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'import warnings\\nwarnings.filterwarnings(\"ignore\"...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...in_df.drop('SalePrice', axis = 1)\\n\\ntest_df.head()\", 'y_train.head()\\nfeat_labels = train_df.columns.values\\n#feat_labels\\nx_train.isnull().values.any()', 'from sklearn.ensemble import RandomForestRegress...ore_r2),np.min(cv_score_r2),np.max(cv_score_r2)))', 'from sklearn.grid_search import GridSearchCV', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'], 'Out': {3:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], 4: False}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': False, '_3':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '_4': False, '__':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '___': '', '__builtin__': <module 'builtins' (built-in)>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', 'import warnings\\nwarnings.filterwarnings(\"ignore\"...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...in_df.drop('SalePrice', axis = 1)\\n\\ntest_df.head()\", 'y_train.head()\\nfeat_labels = train_df.columns.values\\n#feat_labels\\nx_train.isnull().values.any()', 'from sklearn.ensemble import RandomForestRegress...ore_r2),np.min(cv_score_r2),np.max(cv_score_r2)))', 'from sklearn.grid_search import GridSearchCV', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)', '# Tuning max_depth and min_samples_split\\n\\nparam_...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)'], 'Out': {3:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], 4: False}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': False, '_3':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '_4': False, '__':    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 254 columns], '___': '', '__builtin__': <module 'builtins' (built-in)>, ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/saksham/Machine Learning/Kaggle/Housing Prices Prediction/<ipython-input-8-ca3d5ac98d81> in <module>()\n      1 # Tuning max_depth and min_samples_split\n      2 \n      3 param_test2 =  {'max_depth':np.arange(7,9,1), 'min_samples_split':np.arange(1,11,2)}\n      4 rfr = RandomForestRegressor(n_estimators=1500,max_features='sqrt', random_state=0)\n      5 gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test2 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n----> 6 gridSearch2.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='r2', verbose=0)>\n        X =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns]\n        y = 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64\n        self.param_grid = {'max_depth': array([7, 8]), 'min_samples_split': array([1, 3, 5, 7, 9])}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Mar  9 20:06:51 2017\nPID: 3372                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'max_depth': 7, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'max_depth': 7, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...state=0,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 1499\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 1500)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=..._state=0,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=1500, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...        random_state=209652396, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 1.,  1.,  1., ...,  0.,  2.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...         random_state=209652396, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 1.,  1.,  1., ...,  0.,  2.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# Tuning max_depth and min_samples_split\n",
    "\n",
    "param_test2 =  {'max_depth':np.arange(7,9,1), 'min_samples_split':np.arange(1,11,2)}\n",
    "rfr = RandomForestRegressor(n_estimators=1500,max_features='sqrt', random_state=0)\n",
    "gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test2 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n",
    "gridSearch2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.70907, std: 0.01400, params: {'max_depth': 5, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 5, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 5, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 5, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 5, 'min_samples_split': 1000},\n",
       "  mean: 0.71050, std: 0.01405, params: {'max_depth': 7, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 7, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 7, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 7, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 7, 'min_samples_split': 1000},\n",
       "  mean: 0.71055, std: 0.01413, params: {'max_depth': 9, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 9, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 9, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 9, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 9, 'min_samples_split': 1000},\n",
       "  mean: 0.71055, std: 0.01413, params: {'max_depth': 11, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 11, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 11, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 11, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 11, 'min_samples_split': 1000},\n",
       "  mean: 0.71055, std: 0.01413, params: {'max_depth': 13, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 13, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 13, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 13, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 13, 'min_samples_split': 1000},\n",
       "  mean: 0.71055, std: 0.01413, params: {'max_depth': 15, 'min_samples_split': 200},\n",
       "  mean: 0.54627, std: 0.01892, params: {'max_depth': 15, 'min_samples_split': 400},\n",
       "  mean: 0.46493, std: 0.01550, params: {'max_depth': 15, 'min_samples_split': 600},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 15, 'min_samples_split': 800},\n",
       "  mean: -0.00338, std: 0.00473, params: {'max_depth': 15, 'min_samples_split': 1000}],\n",
       " {'max_depth': 9, 'min_samples_split': 200},\n",
       " 0.7105521037744398)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch2.grid_scores_, gridSearch2.best_params_ , gridSearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a really bad score here of 0.71. We will try come back to optimisation of min_sample_split later on . We choose max_depth = 9 as optimum paramter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fe15c64e5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fe15c64e5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E6EEAAEE6A364ACD9ADEF28027FA3F37']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E6EEAAEE6A364ACD9ADEF28027FA3F37'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\"\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-122-60c5fb63bcef>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\ntrain_df... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"import numpy as np # linear algebra\\nimport panda... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', 'from sklearn.ensemble import RandomForestRegressor', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...test_cleaned.csv')\\n\\ntest_df.shape\\ntest_df.columns\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... pd.read_csv('test_cleaned.csv')\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...Id']\\ntrain_df.drop('Id',axis = 1, inplace = True)\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...p('Id',axis = 1, inplace = True)\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...\\ny_train = train_df['SalePrice']\\n\\ntrain_df.head()\", '\\ntrain_df.head()', ...], 'Out': {1: (1459, 255), 2: (1459, 255), 3: (1459, 255), 6: Index(['Id', 'MSSubClass', 'LotFrontage', 'LotAr...or2nd_CBlock'],\n      dtype='object', length=255), 9:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 10:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 12:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 14:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 15:    Id  MSSubClass  LotFrontage   LotArea  Overal... \n4                   0  \n\n[5 rows x 256 columns], 17:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 255 columns], ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': ([mean: 0.80172, std: 0.01473, params: {'min_samples_leaf': 3, 'min_samples_split': 60}, mean: 0.77277, std: 0.01373, params: {'min_samples_leaf': 3, 'min_samples_split': 100}, mean: 0.74661, std: 0.01298, params: {'min_samples_leaf': 3, 'min_samples_split': 140}, mean: 0.72263, std: 0.01311, params: {'min_samples_leaf': 3, 'min_samples_split': 180}, mean: 0.78965, std: 0.00935, params: {'min_samples_leaf': 13, 'min_samples_split': 60}, mean: 0.76161, std: 0.01268, params: {'min_samples_leaf': 13, 'min_samples_split': 100}, mean: 0.74197, std: 0.01123, params: {'min_samples_leaf': 13, 'min_samples_split': 140}, mean: 0.71896, std: 0.01309, params: {'min_samples_leaf': 13, 'min_samples_split': 180}, mean: 0.77485, std: 0.01285, params: {'min_samples_leaf': 23, 'min_samples_split': 60}, mean: 0.75107, std: 0.01385, params: {'min_samples_leaf': 23, 'min_samples_split': 100}, mean: 0.73340, std: 0.01352, params: {'min_samples_leaf': 23, 'min_samples_split': 140}, mean: 0.71338, std: 0.01406, params: {'min_samples_leaf': 23, 'min_samples_split': 180}, mean: 0.75257, std: 0.01011, params: {'min_samples_leaf': 33, 'min_samples_split': 60}, mean: 0.74229, std: 0.01220, params: {'min_samples_leaf': 33, 'min_samples_split': 100}, mean: 0.72337, std: 0.01178, params: {'min_samples_leaf': 33, 'min_samples_split': 140}, mean: 0.70336, std: 0.01211, params: {'min_samples_leaf': 33, 'min_samples_split': 180}, mean: 0.73271, std: 0.01226, params: {'min_samples_leaf': 43, 'min_samples_split': 60}, mean: 0.72552, std: 0.01338, params: {'min_samples_leaf': 43, 'min_samples_split': 100}, mean: 0.71348, std: 0.01316, params: {'min_samples_leaf': 43, 'min_samples_split': 140}, mean: 0.69496, std: 0.01239, params: {'min_samples_leaf': 43, 'min_samples_split': 180}, ...], {'min_samples_leaf': 3, 'min_samples_split': 60}, 0.8017249264607569), '_1': (1459, 255), '_10':      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], '_113': {'max_depth': range(5, 16, 2), 'min_samples_split': range(200, 1001, 200)}, '_114': range(5, 16, 2), '_115': array([ 5,  7,  9, 11, 13, 15]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\ntrain_df... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"import numpy as np # linear algebra\\nimport panda... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', 'from sklearn.ensemble import RandomForestRegressor', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...test_cleaned.csv')\\n\\ntest_df.shape\\ntest_df.columns\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... pd.read_csv('test_cleaned.csv')\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...Id']\\ntrain_df.drop('Id',axis = 1, inplace = True)\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...p('Id',axis = 1, inplace = True)\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...\\ny_train = train_df['SalePrice']\\n\\ntrain_df.head()\", '\\ntrain_df.head()', ...], 'Out': {1: (1459, 255), 2: (1459, 255), 3: (1459, 255), 6: Index(['Id', 'MSSubClass', 'LotFrontage', 'LotAr...or2nd_CBlock'],\n      dtype='object', length=255), 9:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 10:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 12:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 14:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 15:    Id  MSSubClass  LotFrontage   LotArea  Overal... \n4                   0  \n\n[5 rows x 256 columns], 17:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 255 columns], ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': ([mean: 0.80172, std: 0.01473, params: {'min_samples_leaf': 3, 'min_samples_split': 60}, mean: 0.77277, std: 0.01373, params: {'min_samples_leaf': 3, 'min_samples_split': 100}, mean: 0.74661, std: 0.01298, params: {'min_samples_leaf': 3, 'min_samples_split': 140}, mean: 0.72263, std: 0.01311, params: {'min_samples_leaf': 3, 'min_samples_split': 180}, mean: 0.78965, std: 0.00935, params: {'min_samples_leaf': 13, 'min_samples_split': 60}, mean: 0.76161, std: 0.01268, params: {'min_samples_leaf': 13, 'min_samples_split': 100}, mean: 0.74197, std: 0.01123, params: {'min_samples_leaf': 13, 'min_samples_split': 140}, mean: 0.71896, std: 0.01309, params: {'min_samples_leaf': 13, 'min_samples_split': 180}, mean: 0.77485, std: 0.01285, params: {'min_samples_leaf': 23, 'min_samples_split': 60}, mean: 0.75107, std: 0.01385, params: {'min_samples_leaf': 23, 'min_samples_split': 100}, mean: 0.73340, std: 0.01352, params: {'min_samples_leaf': 23, 'min_samples_split': 140}, mean: 0.71338, std: 0.01406, params: {'min_samples_leaf': 23, 'min_samples_split': 180}, mean: 0.75257, std: 0.01011, params: {'min_samples_leaf': 33, 'min_samples_split': 60}, mean: 0.74229, std: 0.01220, params: {'min_samples_leaf': 33, 'min_samples_split': 100}, mean: 0.72337, std: 0.01178, params: {'min_samples_leaf': 33, 'min_samples_split': 140}, mean: 0.70336, std: 0.01211, params: {'min_samples_leaf': 33, 'min_samples_split': 180}, mean: 0.73271, std: 0.01226, params: {'min_samples_leaf': 43, 'min_samples_split': 60}, mean: 0.72552, std: 0.01338, params: {'min_samples_leaf': 43, 'min_samples_split': 100}, mean: 0.71348, std: 0.01316, params: {'min_samples_leaf': 43, 'min_samples_split': 140}, mean: 0.69496, std: 0.01239, params: {'min_samples_leaf': 43, 'min_samples_split': 180}, ...], {'min_samples_leaf': 3, 'min_samples_split': 60}, 0.8017249264607569), '_1': (1459, 255), '_10':      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], '_113': {'max_depth': range(5, 16, 2), 'min_samples_split': range(200, 1001, 200)}, '_114': range(5, 16, 2), '_115': array([ 5,  7,  9, 11, 13, 15]), ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/saksham/Machine Learning/Kaggle/Housing Prices Prediction/<ipython-input-122-60c5fb63bcef> in <module>()\n      1 \n      2 \n      3 param_test1 =  {'min_samples_leaf':np.arange(1,71,6), 'min_samples_split':np.arange(1,200,20)}\n----> 4 rfr = RandomForestRegressor(n_estimators=60,max_depth = 9,max_features='sqrt', random_state=10)\n      5 gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test1 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n      6 gridSearch2.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='r2', verbose=0)>\n        X =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns]\n        y = 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64\n        self.param_grid = {'min_samples_leaf': array([ 1,  7, 13, 19, 25, 31, 37, 43, 49, 55, 61, 67]), 'min_samples_split': array([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181])}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Mar  9 18:33:57 2017\nPID: 1577                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'min_samples_leaf': 1, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...tate=10,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 59\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=60, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...       random_state=1165313289, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  0.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py\", line 1665, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\", line 326, in fit\n    for i, t in enumerate(trees))\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 758, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 608, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 571, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 109, in apply_async\n    result = ImmediateResult(func)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 326, in __init__\n    self.results = batch()\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\", line 120, in _parallel_build_trees\n    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py\", line 1029, in fit\n    X_idx_sorted=X_idx_sorted)\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py\", line 199, in fit\n    % self.min_samples_split)\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/anaconda3/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Mar  9 18:33:57 2017\nPID: 1577                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'min_samples_leaf': 1, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...tate=10,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 59\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=60, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...       random_state=1165313289, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  0.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    681\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'timeout'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Thu Mar  9 18:33:57 2017\nPID: 1577                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'min_samples_leaf': 1, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...tate=10,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 59\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=60, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...       random_state=1165313289, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  0.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-60c5fb63bcef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqrt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgridSearch2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_test1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'r2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0miid\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgridSearch2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m         \"\"\"\n\u001b[1;32m--> 829\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    571\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m                 for train, test in cv)\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    165         sys.exit(msg)\n    166     main_globals = sys.modules[\"__main__\"].__dict__\n    167     if alter_argv:\n    168         sys.argv[0] = mod_spec.origin\n    169     return _run_code(code, main_globals, None,\n--> 170                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    171 \n    172 def run_module(mod_name, init_globals=None,\n    173                run_name=None, alter_sys=False):\n    174     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/root/anaconda3/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x7fe15c64e5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7fe15c64e5d0, file \"/...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/root/anacon.../python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    587         \n    588         If a global instance already exists, this reinitializes and starts it\n    589         \"\"\"\n    590         app = cls.instance(**kwargs)\n    591         app.initialize(argv)\n--> 592         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    593 \n    594 #-----------------------------------------------------------------------------\n    595 # utility functions, for convenience\n    596 #-----------------------------------------------------------------------------\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    398         \n    399         if self.poller is not None:\n    400             self.poller.start()\n    401         self.kernel.start()\n    402         try:\n--> 403             ioloop.IOLoop.instance().start()\n    404         except KeyboardInterrupt:\n    405             pass\n    406 \n    407 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    146             PollIOLoop.configure(ZMQIOLoop)\n    147         return PollIOLoop.instance()\n    148     \n    149     def start(self):\n    150         try:\n--> 151             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    152         except ZMQError as e:\n    153             if e.errno == ETERM:\n    154                 # quietly return on ETERM\n    155                 pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    861                 self._events.update(event_pairs)\n    862                 while self._events:\n    863                     fd, events = self._events.popitem()\n    864                     try:\n    865                         fd_obj, handler_func = self._handlers[fd]\n--> 866                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    867                     except (OSError, IOError) as e:\n    868                         if errno_from_exception(e) == errno.EPIPE:\n    869                             # Happens when the client closes the connection\n    870                             pass\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    428             # dispatch events:\n    429             if events & IOLoop.ERROR:\n    430                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    431                 return\n    432             if events & IOLoop.READ:\n--> 433                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    434                 if not self.socket:\n    435                     return\n    436             if events & IOLoop.WRITE:\n    437                 self._handle_send()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    460                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    461         else:\n    462             if self._recv_callback:\n    463                 callback = self._recv_callback\n    464                 # self._recv_callback = None\n--> 465                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    466                 \n    467         # self.update_state()\n    468         \n    469 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    402         close our socket.\"\"\"\n    403         try:\n    404             # Use a NullContext to ensure that all StackContexts are run\n    405             # inside our blanket exception handler rather than outside.\n    406             with stack_context.NullContext():\n--> 407                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    408         except:\n    409             gen_log.error(\"Uncaught exception, closing connection.\",\n    410                           exc_info=True)\n    411             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    255         if self.control_stream:\n    256             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    257 \n    258         def make_dispatcher(stream):\n    259             def dispatcher(msg):\n--> 260                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    261             return dispatcher\n    262 \n    263         for s in self.shell_streams:\n    264             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}})\n    207             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    208         else:\n    209             self.log.debug(\"%s: %s\", msg_type, msg)\n    210             self.pre_handler_hook()\n    211             try:\n--> 212                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'E6EEAAEE6A364ACD9ADEF28027FA3F37']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}}\n    213             except Exception:\n    214                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    215             finally:\n    216                 self.post_handler_hook()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'E6EEAAEE6A364ACD9ADEF28027FA3F37'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2017-03-09T18:33:55.373574', 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'session': 'E6EEAAEE6A364ACD9ADEF28027FA3F37', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '01116CC4A91C44B6BDDF93064FB3914E', 'msg_type': 'execute_request', 'parent_header': {}})\n    365         if not silent:\n    366             self.execution_count += 1\n    367             self._publish_execute_input(code, parent, self.execution_count)\n    368 \n    369         reply_content = self.do_execute(code, silent, store_history,\n--> 370                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    371 \n    372         # Flush output before sending the reply.\n    373         sys.stdout.flush()\n    374         sys.stderr.flush()\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    170 \n    171         reply_content = {}\n    172         # FIXME: the shell calls the exception handler itself.\n    173         shell._reply_content = None\n    174         try:\n--> 175             shell.run_cell(code, store_history=store_history, silent=silent)\n        shell.run_cell = <bound method InteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\"\n        store_history = True\n        silent = False\n    176         except:\n    177             status = u'error'\n    178             # FIXME: this code right now isn't being used yet by default,\n    179             # because the run_cell() call above directly fires off exception\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"param_test1 =  {'min_samples_leaf':np.arange(1,7...= False , cv =5)\\ngridSearch2.fit(x_train,y_train)\", store_history=True, silent=False, shell_futures=True)\n   2897                 self.displayhook.exec_result = result\n   2898 \n   2899                 # Execute the user code\n   2900                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2901                 self.run_ast_nodes(code_ast.body, cell_name,\n-> 2902                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2903 \n   2904                 # Reset this so later displayed values do not modify the\n   2905                 # ExecutionResult\n   2906                 self.displayhook.exec_result = None\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-122-60c5fb63bcef>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3007                     return True\n   3008 \n   3009             for i, node in enumerate(to_run_interactive):\n   3010                 mod = ast.Interactive([node])\n   3011                 code = compiler(mod, cell_name, \"single\")\n-> 3012                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>\n        result = <IPython.core.interactiveshell.ExecutionResult object>\n   3013                     return True\n   3014 \n   3015             # Flush softspace\n   3016             if softspace(sys.stdout, 0):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>, result=<IPython.core.interactiveshell.ExecutionResult object>)\n   3061         outflag = 1  # happens in more places, so it's easier as default\n   3062         try:\n   3063             try:\n   3064                 self.hooks.pre_run_code_hook()\n   3065                 #rprint('Running code', repr(code_obj)) # dbg\n-> 3066                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7fe11e458f60, file \"<ipython-input-122-60c5fb63bcef>\", line 4>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\ntrain_df... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"import numpy as np # linear algebra\\nimport panda... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', 'from sklearn.ensemble import RandomForestRegressor', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...test_cleaned.csv')\\n\\ntest_df.shape\\ntest_df.columns\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... pd.read_csv('test_cleaned.csv')\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...Id']\\ntrain_df.drop('Id',axis = 1, inplace = True)\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...p('Id',axis = 1, inplace = True)\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...\\ny_train = train_df['SalePrice']\\n\\ntrain_df.head()\", '\\ntrain_df.head()', ...], 'Out': {1: (1459, 255), 2: (1459, 255), 3: (1459, 255), 6: Index(['Id', 'MSSubClass', 'LotFrontage', 'LotAr...or2nd_CBlock'],\n      dtype='object', length=255), 9:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 10:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 12:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 14:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 15:    Id  MSSubClass  LotFrontage   LotArea  Overal... \n4                   0  \n\n[5 rows x 256 columns], 17:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 255 columns], ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': ([mean: 0.80172, std: 0.01473, params: {'min_samples_leaf': 3, 'min_samples_split': 60}, mean: 0.77277, std: 0.01373, params: {'min_samples_leaf': 3, 'min_samples_split': 100}, mean: 0.74661, std: 0.01298, params: {'min_samples_leaf': 3, 'min_samples_split': 140}, mean: 0.72263, std: 0.01311, params: {'min_samples_leaf': 3, 'min_samples_split': 180}, mean: 0.78965, std: 0.00935, params: {'min_samples_leaf': 13, 'min_samples_split': 60}, mean: 0.76161, std: 0.01268, params: {'min_samples_leaf': 13, 'min_samples_split': 100}, mean: 0.74197, std: 0.01123, params: {'min_samples_leaf': 13, 'min_samples_split': 140}, mean: 0.71896, std: 0.01309, params: {'min_samples_leaf': 13, 'min_samples_split': 180}, mean: 0.77485, std: 0.01285, params: {'min_samples_leaf': 23, 'min_samples_split': 60}, mean: 0.75107, std: 0.01385, params: {'min_samples_leaf': 23, 'min_samples_split': 100}, mean: 0.73340, std: 0.01352, params: {'min_samples_leaf': 23, 'min_samples_split': 140}, mean: 0.71338, std: 0.01406, params: {'min_samples_leaf': 23, 'min_samples_split': 180}, mean: 0.75257, std: 0.01011, params: {'min_samples_leaf': 33, 'min_samples_split': 60}, mean: 0.74229, std: 0.01220, params: {'min_samples_leaf': 33, 'min_samples_split': 100}, mean: 0.72337, std: 0.01178, params: {'min_samples_leaf': 33, 'min_samples_split': 140}, mean: 0.70336, std: 0.01211, params: {'min_samples_leaf': 33, 'min_samples_split': 180}, mean: 0.73271, std: 0.01226, params: {'min_samples_leaf': 43, 'min_samples_split': 60}, mean: 0.72552, std: 0.01338, params: {'min_samples_leaf': 43, 'min_samples_split': 100}, mean: 0.71348, std: 0.01316, params: {'min_samples_leaf': 43, 'min_samples_split': 140}, mean: 0.69496, std: 0.01239, params: {'min_samples_leaf': 43, 'min_samples_split': 180}, ...], {'min_samples_leaf': 3, 'min_samples_split': 60}, 0.8017249264607569), '_1': (1459, 255), '_10':      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], '_113': {'max_depth': range(5, 16, 2), 'min_samples_split': range(200, 1001, 200)}, '_114': range(5, 16, 2), '_115': array([ 5,  7,  9, 11, 13, 15]), ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\n\\ntrain_df... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"import numpy as np # linear algebra\\nimport panda... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... = pd.read_csv('test_cleaned.csv')\\n\\ntest_df.shape\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', 'from sklearn.ensemble import RandomForestRegressor', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...test_cleaned.csv')\\n\\ntest_df.shape\\ntest_df.columns\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest....csv')\\n\\ntest_df.shape\\ntest_df['SalePrice'].head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", 'import numpy as np # linear algebra\\nimport panda...tebook\")\\nget_ipython().magic(\\'matplotlib inline\\')', \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...= pd.read_csv('test_cleaned.csv')\\n\\ntest_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest... pd.read_csv('test_cleaned.csv')\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...Id']\\ntrain_df.drop('Id',axis = 1, inplace = True)\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...p('Id',axis = 1, inplace = True)\\n\\ntrain_df.head()\", \"train_df = pd.read_csv('train_cleaned.csv')\\ntest...\\ny_train = train_df['SalePrice']\\n\\ntrain_df.head()\", '\\ntrain_df.head()', ...], 'Out': {1: (1459, 255), 2: (1459, 255), 3: (1459, 255), 6: Index(['Id', 'MSSubClass', 'LotFrontage', 'LotAr...or2nd_CBlock'],\n      dtype='object', length=255), 9:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 10:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 12:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 14:      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], 15:    Id  MSSubClass  LotFrontage   LotArea  Overal... \n4                   0  \n\n[5 rows x 256 columns], 17:    MSSubClass  LotFrontage   LotArea  OverallQua...  0                   0  \n\n[5 rows x 255 columns], ...}, 'RandomForestRegressor': <class 'sklearn.ensemble.forest.RandomForestRegressor'>, '_': ([mean: 0.80172, std: 0.01473, params: {'min_samples_leaf': 3, 'min_samples_split': 60}, mean: 0.77277, std: 0.01373, params: {'min_samples_leaf': 3, 'min_samples_split': 100}, mean: 0.74661, std: 0.01298, params: {'min_samples_leaf': 3, 'min_samples_split': 140}, mean: 0.72263, std: 0.01311, params: {'min_samples_leaf': 3, 'min_samples_split': 180}, mean: 0.78965, std: 0.00935, params: {'min_samples_leaf': 13, 'min_samples_split': 60}, mean: 0.76161, std: 0.01268, params: {'min_samples_leaf': 13, 'min_samples_split': 100}, mean: 0.74197, std: 0.01123, params: {'min_samples_leaf': 13, 'min_samples_split': 140}, mean: 0.71896, std: 0.01309, params: {'min_samples_leaf': 13, 'min_samples_split': 180}, mean: 0.77485, std: 0.01285, params: {'min_samples_leaf': 23, 'min_samples_split': 60}, mean: 0.75107, std: 0.01385, params: {'min_samples_leaf': 23, 'min_samples_split': 100}, mean: 0.73340, std: 0.01352, params: {'min_samples_leaf': 23, 'min_samples_split': 140}, mean: 0.71338, std: 0.01406, params: {'min_samples_leaf': 23, 'min_samples_split': 180}, mean: 0.75257, std: 0.01011, params: {'min_samples_leaf': 33, 'min_samples_split': 60}, mean: 0.74229, std: 0.01220, params: {'min_samples_leaf': 33, 'min_samples_split': 100}, mean: 0.72337, std: 0.01178, params: {'min_samples_leaf': 33, 'min_samples_split': 140}, mean: 0.70336, std: 0.01211, params: {'min_samples_leaf': 33, 'min_samples_split': 180}, mean: 0.73271, std: 0.01226, params: {'min_samples_leaf': 43, 'min_samples_split': 60}, mean: 0.72552, std: 0.01338, params: {'min_samples_leaf': 43, 'min_samples_split': 100}, mean: 0.71348, std: 0.01316, params: {'min_samples_leaf': 43, 'min_samples_split': 140}, mean: 0.69496, std: 0.01239, params: {'min_samples_leaf': 43, 'min_samples_split': 180}, ...], {'min_samples_leaf': 3, 'min_samples_split': 60}, 0.8017249264607569), '_1': (1459, 255), '_10':      Id  MSSubClass  LotFrontage   LotArea  Over...  0                   0  \n\n[5 rows x 255 columns], '_113': {'max_depth': range(5, 16, 2), 'min_samples_split': range(200, 1001, 200)}, '_114': range(5, 16, 2), '_115': array([ 5,  7,  9, 11, 13, 15]), ...}\n   3067             finally:\n   3068                 # Reset our crash handler in place\n   3069                 sys.excepthook = old_excepthook\n   3070         except SystemExit as e:\n\n...........................................................................\n/home/saksham/Machine Learning/Kaggle/Housing Prices Prediction/<ipython-input-122-60c5fb63bcef> in <module>()\n      1 \n      2 \n      3 param_test1 =  {'min_samples_leaf':np.arange(1,71,6), 'min_samples_split':np.arange(1,200,20)}\n----> 4 rfr = RandomForestRegressor(n_estimators=60,max_depth = 9,max_features='sqrt', random_state=10)\n      5 gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test1 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n      6 gridSearch2.fit(x_train,y_train)\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64)\n    824         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    825             Target relative to X for classification or regression;\n    826             None for unsupervised learning.\n    827 \n    828         \"\"\"\n--> 829         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring='r2', verbose=0)>\n        X =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns]\n        y = 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64\n        self.param_grid = {'min_samples_leaf': array([ 1,  7, 13, 19, 25, 31, 37, 43, 49, 55, 61, 67]), 'min_samples_split': array([  1,  21,  41,  61,  81, 101, 121, 141, 161, 181])}\n    830 \n    831 \n    832 class RandomizedSearchCV(BaseSearchCV):\n    833     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...='2*n_jobs', refit=True, scoring='r2', verbose=0), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    568         )(\n    569             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    570                                     train, test, self.verbose, parameters,\n    571                                     self.fit_params, return_parameters=True,\n    572                                     error_score=self.error_score)\n--> 573                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    574                 for train, test in cv)\n    575 \n    576         # Out is a list of triplet: score, estimator, n_test_samples\n    577         n_fits = len(out)\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Thu Mar  9 18:33:57 2017\nPID: 1577                         Python 3.5.0: /root/anaconda3/bin/python3\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False),       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], 0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, make_scorer(r2_score), array([ 292,  293,  294, ..., 1457, 1458, 1459]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), 0, {'min_samples_leaf': 1, 'min_samples_split': 1}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py in _fit_and_score(estimator=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=      MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1460 rows x 254 columns], y=0       12.247699\n1       12.109016\n2       12.3...1459    11.901590\nName: SalePrice, dtype: float64, scorer=make_scorer(r2_score), train=array([ 292,  293,  294, ..., 1457, 1458, 1459]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ..., 284, 285,\n       286, 287, 288, 289, 290, 291]), verbose=0, parameters={'min_samples_leaf': 1, 'min_samples_split': 1}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1660 \n   1661     try:\n   1662         if y_train is None:\n   1663             estimator.fit(X_train, **fit_params)\n   1664         else:\n-> 1665             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestRegr...tate=10,\n           verbose=0, warm_start=False)>\n        X_train =       MSSubClass  LotFrontage    LotArea  Overal...                   0  \n\n[1168 rows x 254 columns]\n        y_train = 292     11.782960\n293     12.367345\n294     12.0...1459    11.901590\nName: SalePrice, dtype: float64\n        fit_params = {}\n   1666 \n   1667     except Exception as e:\n   1668         if error_score == 'raise':\n   1669             raise\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in fit(self=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None)\n    321             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n    322                              backend=\"threading\")(\n    323                 delayed(_parallel_build_trees)(\n    324                     t, self, X, y, sample_weight, i, len(trees),\n    325                     verbose=self.verbose, class_weight=self.class_weight)\n--> 326                 for i, t in enumerate(trees))\n        i = 59\n    327 \n    328             # Collect newly grown trees\n    329             self.estimators_.extend(trees)\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    753         self.n_completed_tasks = 0\n    754         try:\n    755             # Only set self._iterating to True if at least a batch\n    756             # was dispatched. In particular this covers the edge\n    757             # case of Parallel used with an exhausted iterator.\n--> 758             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object BaseForest.fit.<locals>.<genexpr>>\n    759                 self._iterating = True\n    760             else:\n    761                 self._iterating = False\n    762 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object BaseForest.fit.<locals>.<genexpr>>)\n    603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    604             if len(tasks) == 0:\n    605                 # No more tasks available in the iterator: tell caller to stop.\n    606                 return False\n    607             else:\n--> 608                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    609                 return True\n    610 \n    611     def _print(self, msg, msg_args):\n    612         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    566         self.n_dispatched_tasks += len(batch)\n    567         self.n_dispatched_batches += 1\n    568 \n    569         dispatch_timestamp = time.time()\n    570         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 571         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    572         self._jobs.append(job)\n    573 \n    574     def dispatch_next(self):\n    575         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    104             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    105         return 1\n    106 \n    107     def apply_async(self, func, callback=None):\n    108         \"\"\"Schedule a func to be run\"\"\"\n--> 109         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    110         if callback:\n    111             callback(result)\n    112         return result\n    113 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    321 \n    322 class ImmediateResult(object):\n    323     def __init__(self, batch):\n    324         # Don't delay the application, to avoid keeping the input\n    325         # arguments in memory\n--> 326         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    327 \n    328     def get(self):\n    329         return self.results\n    330 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _parallel_build_trees>, (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60), {'class_weight': None, 'verbose': 0})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _parallel_build_trees>\n        args = (DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), None, 0, 60)\n        kwargs = {'class_weight': None, 'verbose': 0}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), forest=RandomForestRegressor(bootstrap=True, criterion=...state=10,\n           verbose=0, warm_start=False), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=None, tree_idx=0, n_trees=60, verbose=0, class_weight=None)\n    115                 warnings.simplefilter('ignore', DeprecationWarning)\n    116                 curr_sample_weight *= compute_sample_weight('auto', y, indices)\n    117         elif class_weight == 'balanced_subsample':\n    118             curr_sample_weight *= compute_sample_weight('balanced', y, indices)\n    119 \n--> 120         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n        tree.fit = <bound method DecisionTreeRegressor.fit of Decis...       random_state=1165313289, splitter='best')>\n        X = array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32)\n        y = array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]])\n        sample_weight = None\n        curr_sample_weight = array([ 0.,  0.,  0., ...,  0.,  1.,  1.])\n    121     else:\n    122         tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n    123 \n    124     return tree\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n   1024 \n   1025         super(DecisionTreeRegressor, self).fit(\n   1026             X, y,\n   1027             sample_weight=sample_weight,\n   1028             check_input=check_input,\n-> 1029             X_idx_sorted=X_idx_sorted)\n        X_idx_sorted = None\n   1030         return self\n   1031 \n   1032 \n   1033 class ExtraTreeClassifier(DecisionTreeClassifier):\n\n...........................................................................\n/root/anaconda3/lib/python3.5/site-packages/sklearn/tree/tree.py in fit(self=DecisionTreeRegressor(criterion='mse', max_depth...        random_state=1165313289, splitter='best'), X=array([[ 3.93182564,  4.1108737 ,  9.3422451 , ....        0.        ,  0.        ]], dtype=float32), y=array([[ 11.78296024],\n       [ 12.36734505],\n  ...],\n       [ 11.86446927],\n       [ 11.90159023]]), sample_weight=array([ 0.,  0.,  0., ...,  0.,  1.,  1.]), check_input=False, X_idx_sorted=None)\n    194 \n    195         if isinstance(self.min_samples_split, (numbers.Integral, np.integer)):\n    196             if not 2 <= self.min_samples_split:\n    197                 raise ValueError(\"min_samples_split must be at least 2 \"\n    198                                  \"or in (0, 1], got %s\"\n--> 199                                  % self.min_samples_split)\n        self.min_samples_split = 1\n    200             min_samples_split = self.min_samples_split\n    201         else:  # float\n    202             if not 0. < self.min_samples_split <= 1.:\n    203                 raise ValueError(\"min_samples_split must be at least 2 \"\n\nValueError: min_samples_split must be at least 2 or in (0, 1], got 1\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "param_test1 =  {'min_samples_leaf':np.arange(1,71,6), 'min_samples_split':np.arange(1,200,20)}\n",
    "rfr = RandomForestRegressor(n_estimators=60,max_depth = 9,max_features='sqrt', random_state=10)\n",
    "gridSearch2 = GridSearchCV(estimator = rfr , param_grid = param_test1 , scoring = 'r2',n_jobs = -1 , iid= False , cv =5)\n",
    "gridSearch2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.80172, std: 0.01473, params: {'min_samples_leaf': 3, 'min_samples_split': 60},\n",
       "  mean: 0.77277, std: 0.01373, params: {'min_samples_leaf': 3, 'min_samples_split': 100},\n",
       "  mean: 0.74661, std: 0.01298, params: {'min_samples_leaf': 3, 'min_samples_split': 140},\n",
       "  mean: 0.72263, std: 0.01311, params: {'min_samples_leaf': 3, 'min_samples_split': 180},\n",
       "  mean: 0.78965, std: 0.00935, params: {'min_samples_leaf': 13, 'min_samples_split': 60},\n",
       "  mean: 0.76161, std: 0.01268, params: {'min_samples_leaf': 13, 'min_samples_split': 100},\n",
       "  mean: 0.74197, std: 0.01123, params: {'min_samples_leaf': 13, 'min_samples_split': 140},\n",
       "  mean: 0.71896, std: 0.01309, params: {'min_samples_leaf': 13, 'min_samples_split': 180},\n",
       "  mean: 0.77485, std: 0.01285, params: {'min_samples_leaf': 23, 'min_samples_split': 60},\n",
       "  mean: 0.75107, std: 0.01385, params: {'min_samples_leaf': 23, 'min_samples_split': 100},\n",
       "  mean: 0.73340, std: 0.01352, params: {'min_samples_leaf': 23, 'min_samples_split': 140},\n",
       "  mean: 0.71338, std: 0.01406, params: {'min_samples_leaf': 23, 'min_samples_split': 180},\n",
       "  mean: 0.75257, std: 0.01011, params: {'min_samples_leaf': 33, 'min_samples_split': 60},\n",
       "  mean: 0.74229, std: 0.01220, params: {'min_samples_leaf': 33, 'min_samples_split': 100},\n",
       "  mean: 0.72337, std: 0.01178, params: {'min_samples_leaf': 33, 'min_samples_split': 140},\n",
       "  mean: 0.70336, std: 0.01211, params: {'min_samples_leaf': 33, 'min_samples_split': 180},\n",
       "  mean: 0.73271, std: 0.01226, params: {'min_samples_leaf': 43, 'min_samples_split': 60},\n",
       "  mean: 0.72552, std: 0.01338, params: {'min_samples_leaf': 43, 'min_samples_split': 100},\n",
       "  mean: 0.71348, std: 0.01316, params: {'min_samples_leaf': 43, 'min_samples_split': 140},\n",
       "  mean: 0.69496, std: 0.01239, params: {'min_samples_leaf': 43, 'min_samples_split': 180},\n",
       "  mean: 0.70885, std: 0.01432, params: {'min_samples_leaf': 53, 'min_samples_split': 60},\n",
       "  mean: 0.70885, std: 0.01432, params: {'min_samples_leaf': 53, 'min_samples_split': 100},\n",
       "  mean: 0.69880, std: 0.01364, params: {'min_samples_leaf': 53, 'min_samples_split': 140},\n",
       "  mean: 0.68294, std: 0.01037, params: {'min_samples_leaf': 53, 'min_samples_split': 180},\n",
       "  mean: 0.68798, std: 0.01469, params: {'min_samples_leaf': 63, 'min_samples_split': 60},\n",
       "  mean: 0.68798, std: 0.01469, params: {'min_samples_leaf': 63, 'min_samples_split': 100},\n",
       "  mean: 0.68422, std: 0.01371, params: {'min_samples_leaf': 63, 'min_samples_split': 140},\n",
       "  mean: 0.66834, std: 0.01036, params: {'min_samples_leaf': 63, 'min_samples_split': 180}],\n",
       " {'min_samples_leaf': 3, 'min_samples_split': 60},\n",
       " 0.8017249264607569)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearch2.grid_scores_, gridSearch2.best_params_ , gridSearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
