{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "style.use('ggplot')                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    \n",
    "    def __init__(self,visualization = True):\n",
    "        self.visualization = visualization \n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            \n",
    "    def fit(self,data):\n",
    "        self.data = data \n",
    "        # { ||w|| : [w,b]}\n",
    "        opt_dict = {}       \n",
    "        transforms = [[1,1],\n",
    "                     [-1,1],\n",
    "                     [-1,-1],\n",
    "                     [1,-1]]\n",
    "        \n",
    "        all_data = [[]]\n",
    "        for yi in self.data:\n",
    "            for featureset in self.data[yi]:\n",
    "                for feature in featureset : \n",
    "                    all_data.append(feature)\n",
    "                    \n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        all_data = None\n",
    "        \n",
    "        # support vectors yi(xi.w + b) =1 \n",
    "\n",
    "        step_sizes = [self.max_feature_value * 0.1,\n",
    "                      self.max_feature_value * 0.01,\n",
    "                      # point of expense\n",
    "                      self.max_feature_value * 0.001,] # size of steps\n",
    "        \n",
    "                        # you can thread each step simultaneously\n",
    "            \n",
    "        # extremely expensive\n",
    "        b_range_multiple = 5 # b does not have to take more precise as w does\n",
    "        # we dont need to take as samll steps with b as we do with b\n",
    "        b_multiple = 5\n",
    "        \n",
    "        latest_optimum = self.max_feature_value * 10 \n",
    "        \n",
    "        # Begin actual stepping processes\n",
    "    \n",
    "        for step in step_sizes:\n",
    "            w = np.array([latest_optmimum,latest_optimum])\n",
    "            \n",
    "            # we can do thuis because convex\n",
    "            optimized = False\n",
    "            while not optmized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    for transformation in transforms:\n",
    "                        w_t = w*transformation\n",
    "                        found_option = True\n",
    "                        # weakest link in svm fundamentally\n",
    "                        # SMO attempts to fix this in a bit . Run this function on all the data\n",
    "                        # yi(xi.w + b) > =1\n",
    "                        for i in self.data\n",
    "                            for xi in self.data[i]:\n",
    "                                yi = i\n",
    "                                if not yi*(np.dot(w_t,xi) + b) >=1:\n",
    "                                    found_option = False # we bgin with this option set equal to true . But even one sample does not\\\n",
    "                                                        # satisfy the constraint , we throw this data and begin again \n",
    "                    \n",
    "                         if found_option : # we are checking for each of the transforms \n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "                \n",
    "                \n",
    "                # when we have finished running after every b option and transformation option , we are going to check ::::::\n",
    "                if w[0] < 0 :\n",
    "                    optmized = True\n",
    "                    print('Optmized a step')\n",
    "                    \n",
    "                else:\n",
    "                    # w = [5,5]\n",
    "                    # step = 1\n",
    "                    # w - step = [4,4]\n",
    "                    w = w -step\n",
    "                    \n",
    "            norms = sorted([n for n in opt_dict]) # magnitudes \n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            \n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optmimum = opt_choice[0][0] + step*2        \n",
    "        \n",
    "   \n",
    "    def predict(self,features):\n",
    "        # sign (x.w + b)\n",
    "        classification = np.sign(np.array(features),self.w) + self.b)\n",
    "        if classification ! = 0 amd self.visualization\n",
    "            self.ax.scatter(features[0],features[1], s = 200 . marker =* , c= self.colors[classification])\n",
    "        \n",
    "        return classification \n",
    "    \n",
    "    def visualization(self):\n",
    "        [[self.ax.scatter(x[0],x[1],color = self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "    \n",
    "        # hyperplane = x.w + b\n",
    "        # v = x.w + b\n",
    "        # psv = 1\n",
    "        # nsv = -1\n",
    "        # dec = 0\n",
    "        def hyperplane ( x, w , b , v):\n",
    "            return (-w[0]*x -b +v)/w[1]\n",
    "        \n",
    "        \n",
    "        datarange = (self.min_feature_value*0.9 , self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        \n",
    "\n",
    "        # (w.x+b) = 1\n",
    "        # positive support vector hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[psv1,psv2], 'k')\n",
    "\n",
    "        # (w.x+b) = -1\n",
    "        # negative support vector hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[nsv1,nsv2], 'k')\n",
    "\n",
    "        # (w.x+b) = 0\n",
    "        # positive support vector hyperplane\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max],[db1,db2], 'y--')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]), \n",
    "                 1:np.array([[5,1],\n",
    "                            [6,1],\n",
    "                            [7,3],])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
