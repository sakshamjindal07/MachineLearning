{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived                                             name     sex  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
      "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
      "\n",
      "       age  sibsp  parch  ticket      fare    cabin embarked boat  body  \\\n",
      "0  29.0000      0      0   24160  211.3375       B5        S    2   NaN   \n",
      "1   0.9167      1      2  113781  151.5500  C22 C26        S   11   NaN   \n",
      "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN   NaN   \n",
      "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN   135   \n",
      "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN   NaN   \n",
      "\n",
      "                         home.dest  \n",
      "0                     St Louis, MO  \n",
      "1  Montreal, PQ / Chesterville, ON  \n",
      "2  Montreal, PQ / Chesterville, ON  \n",
      "3  Montreal, PQ / Chesterville, ON  \n",
      "4  Montreal, PQ / Chesterville, ON  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing,cross_validation\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"titanic.xls\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert first into a numerical data -: sex ----> numerical data \n",
    "\n",
    "df.drop(['body','name'],1,inplace=True)\n",
    "df.head()\n",
    "df.fillna(0,inplace=True) #useful for filling empty cell in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived  sex      age  sibsp  parch  ticket      fare  cabin  \\\n",
      "0       1         1    1  29.0000      0      0     740  211.3375    161   \n",
      "1       1         1    0   0.9167      1      2     495  151.5500     66   \n",
      "2       1         0    1   2.0000      1      2     495  151.5500     66   \n",
      "3       1         0    0  30.0000      1      2     495  151.5500     66   \n",
      "4       1         0    1  25.0000      1      2     495  151.5500     66   \n",
      "\n",
      "   embarked  boat  home.dest  \n",
      "0         1     2         52  \n",
      "1         1     9        336  \n",
      "2         1     0        336  \n",
      "3         1     0        336  \n",
      "4         1     0        336  \n"
     ]
    }
   ],
   "source": [
    "#Hanling non numeric data \n",
    "\n",
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "    \n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        \n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "        \n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x=0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "                    \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "            \n",
    "    return df\n",
    "\n",
    "df = handle_non_numerical_data(df)\n",
    "print(df.head())\n",
    "                \n",
    "df.drop(['ticket'],1,inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
    "\n",
    "class K_Means:\n",
    "    \n",
    "    def __init__(self,k=2,tol=0.0001,max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    def fit(self,data):\n",
    "        self.centroids = {}\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "            \n",
    "        for i in range(self.max_iter):\n",
    "            self.classifications ={}\n",
    "            \n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "             \n",
    "            # for each of the featureset we are assigning it to a particular cluster by minising the distance of the particuaar\n",
    "            # centroid of the corresponding cluster\n",
    "            \n",
    "            for featureset in data:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "                \n",
    "            prev_centroids = dict(self.centroids)\n",
    "            \n",
    "            ##  ressigning the centroid of the cluster by recalculating the centroid of each cluster . After that we will again reclassify\n",
    "            \n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "                \n",
    "            optimized = True\n",
    "            \n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "            \n",
    "            if np.sum((current_centroid - original_centroid)/original_centroid *100.0) > self.tol :\n",
    "                print(np.sum((current_centroid - original_centroid)/original_centroid *100.0))\n",
    "                optimized = False\n",
    "                \n",
    "            if optimized:\n",
    "                break\n",
    "\n",
    "    def predict(self,data):\n",
    "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ..., 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.5/site-packages/sklearn/base.py:175: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  args, varargs, kw, default = inspect.getargspec(init)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop(['survived'],1).astype(float))\n",
    "#scaling the data \n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "print(y)\n",
    "\n",
    "clf = KMeans(n_clusters=2)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288006111535523\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1,len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "        \n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
